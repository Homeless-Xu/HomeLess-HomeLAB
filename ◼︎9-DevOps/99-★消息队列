🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 RPC 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 RPC 
    RPC 是指远程调用.  
    两台服务器A、B, 
    RPC 可以让一个部署在A服务器上的应用调用一个部署在B服务器上的另一个应用提供的函数/方法.
    由于不在一个内存空间. 不能直接调用. 需要通过网络来实现!


    ⦿ 首先，要解决通讯的问题，
        主要是通过在客户端和服务器之间建立TCP连接，远程过程调用的所有交换的数据都在这个连接里传输。
        连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。

    ⦿ 第二，要解决寻址的问题，
        也就是说，A服务器上的应用怎么告诉底层的RPC框架，
        如何连接到B服务器（如主机或IP地址）以及特定的端口，方法的名称名称是什么，这样才能完成调用。
        比如基于Web服务协议栈的RPC，就要提供一个endpoint URI，或者是从UDDI服务上查找。
        如果是RMI调用的话，还需要一个RMI Registry来注册服务的地址。

    ⦿ 第三
        当A服务器上的应用发起远程过程调用时，方法的参数需要通过底层的网络协议如TCP传递到B服务器，
        由于网络协议是基于二进制的，内存中的参数的值要序列化成二进制的形式，
        也就是序列化（Serialize）或编组（marshal），通过寻址和传输将序列化的二进制发送给B服务器。

    ⦿ 第四
        B服务器收到请求后，需要对参数进行反序列化（序列化的逆操作），恢复为内存中的表达方式，
        然后找到对应的方法（寻址的一部分）进行本地调用，然后得到返回值。


    ⦿ 第五
        返回值还要发送回服务器A上的应用，也要经过序列化的方式发送，
        服务器A接到后，再反序列化，恢复为内存中的表达方式，交给A服务器上的应用



🔸 为什么用RPC

    就是无法在一个进程内，甚至一个计算机内通过本地调用的方式完成的需求，
    比如比如不同的系统间的通讯，甚至不同的组织间的通讯。
    由于计算能力需要横向扩展，需要在多台机器组成的集群上部署应用，

    RPC的协议有很多, Rest API 就是.




🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 消息队列 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 简介

    消息队列中间件是分布式系统中重要的组件，
    主要解决应用耦合、异步消息、流量削锋等问题。
    实现高性能、高可用、可伸缩和最终一致性架构。是大型分布式系统不可缺少的中间件。

    消息队列已经逐渐成为企业IT系统内部通信的核心手段。

    目前在生产环境，使用较多的消息队列有ActiveMQ、RabbitMQ、ZeroMQ、Kafka、MetaMQ、RocketMQ等。



🔸 通俗解释

    消息队列 = 消息 + 队列

    比如一整天的安排可以看成各种小任务组成的. 小任务就是这里的消息.
    一天可以做很多事情, 但是你不可能同时做很多事情! 所以你需要管理! 
    也就是对各种任务进行排序.把紧急的事情排早上,非紧急的排下午.这就是队列! 

    对于计算机来说, 消息就是各种程序产生的信息.

    队列的操作有 入队和出队
        一个程序产生的消息加入到队列中,就是入队 ➜ 生产者 
        另一个程序读取队列里面的内容,也就是出队 ➜ 消费者


🔸 消息队列  MQ (Message Queue)

    从字面意思上看，本质是个队列，FIFO先入先出，只不过队列中存放的内容是message而已。
    其主要用途：不同进程Process/线程Thread之间通信。
    为什么会产生消息队列？这个问题问的好，我大概查了一下，没有查到最初产生消息队列的背景，但我猜测可能几个原因：

    不同进程（process）之间传递消息时，两个进程之间耦合程度过高，改动一个进程，引发必须修改另一个进程，为了隔离这两个进程，在两进程间抽离出一层（一个模块），所有两进程之间传递的消息，都必须通过消息队列来传递，单独修改某一个进程，不会影响另一个；
    不同进程（process）之间传递消息时，为了实现标准化，将消息的格式规范化了，并且，某一个进程接受的消息太多，一下子无法处理完，并且也有先后顺序，必须对收到的消息进行排队，因此诞生了事实上的消息队列；
    不管到底是什么原因催生了消息队列，总之，上面两个猜测是其实际应用的典型场景。



    在计算机科学中，消息队列和邮箱是用于进程间通信或同一进程内的线程间通信的软件工程组件。
    也就是下面说的第一种. 但是我们常说的消息队列其实指的是下面的第二种.

    消息队列提供一个异步通信协议. 
    异步意味着消息的发送者和接收者不需要在同一时间与消息队列进行交互.
    发送者发送的消息会储存在队列中,直到接收者拿到它.

    一般我们把消息的发送者称为生产者. 消息的接收者称为消费者.

    消息队列 通常会提供额外功能.  确保系统故障时消息不会丢失. 这种消息队列软件 也叫面向消息的中间件.

    一般我们根据生产者和消费者的不同 把队列分成两类.

    1) 操作系统、应用程序内部. 进程之间或者线程之间.
      生产者负责生产,把生产的结果放到缓冲区域(如共享数组)
      消费者从缓冲区取出数据进行消费. 这个缓冲区就称为 消息队列.

    2) ★ 跨应用、跨机器、跨平台的消息队列. 这就是我们常说的消息队列
      队列产品除了消息的传递,还提供相应的可靠性,事物,分布式等特性.将生产者、消费者从中解耦.
      常见的消费队列产品根据是否开源划分为两类!

        收费软件: IBM WebSphere MQ，MSMQ…
        开源软件: ActiveMQ、RabbitMQ、❗️Kafka❗️...




🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 使用场景 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸
🔸 参考  

    ★★★★★ 消息队列技术介绍  http://www.jianshu.com/p/689ce4205021
    ★★★★★ 消息队列技术介绍  http://www.jianshu.com/p/689ce4205021
    ★★★★★ 消息队列技术介绍  http://www.jianshu.com/p/689ce4205021


🔸 使用场景

    技术都是解决问题的! 消息队列解决的是 将突发的大量请求 转换为后端能承受的队列请求!

    就像环法自行车赛, 是分很多天完成的! 你非要让运动员在一天内完成,再厉害的车手也要被你逼死.
    
    电脑也一样! 电脑每秒能处理的任务是有极限的.你得安排好才能让电脑正常运行.

    当企业刚开始 网站访问量不高. 你不需要管理电脑就能轻松处理.
    但是当企业开始快速发展, 访问量飙升, 这时候就要用 消息队列 来缓解服务器的峰值压力.
    比如电脑一秒只能接受100人的网页浏览. 但是你搞宣传 一秒来了1000人.
    这时间你就必须用消息队列. 把1000人分成10组, 一次100人, 10秒后服务器也能处理完成.
    如果你不用消息队列, 一秒直接来1000人,
    脾气好的服务器可能只会web服务没有响应,服务器还正常,电脑还是开着的
    脾气差的服务器就会直接死机给你看...教你做人....
    当然对于这种 web 访问. 用户对时间观念是非常强的! 
    很少用户愿意为了访问某个网站而等上10秒. 所以你的用户流失非常大.
    这时候增加服务器的处理能力才是最重要的. 用消息队列不是一个明智的选择.

    消息队列的功能你知道了,那么什么时候用消息队列才好呢!?

    当某些任务不需要立即获得结果，服务器的并发处理能力不是很强的情况就是你需要使用消息队列的时候.
    
    不紧急的任务可以暂时存在在消息队列中，
    务器根据自身的负载处理能力 尽量处理任务,减小在大并发访问时候的压力。


    ⦿ 例一

        比如你的服务器一秒能处理 100个订单, 但是做活动的时候 一秒进来1000个订单.
        在后端服务器处理能力无法增加的情况下. 你就可以把这个1000个订单 放到队列里面!
        然后后端根据自己的能力处理! 10秒钟也就处理完了.
        如果你不用队列! 那么服务器/程序会直接死机或者无响应 导致订单数据丢失

    ⦿ 例二

        用户注册后必须要给用户发一封邮件!
        服务器每秒只能处理100个用户的注册,每秒用户注册量超出100.就会导致某些用户收不到邮件.
        这时候就需要用消息队列. 一次处理100. 其余的排好队慢慢来.

    ⦿ 例三

        再比如现在的注册都非常智能! 你注册好就有各种个性化设置! 
        就像当年的人人,一注册好就会显示你的各种朋友! 这种功能都是需要花不少时间来计算的! 
        一旦你注册 就会触发很多事件! 当然最基本的是把你的注册信息加到数据库中.
        至于那些显示你的朋友这些额外的功能.完全不需要在注册的时候同时进行.
        但是这些额外功能又是必须的! 所以可以把这些额外功能 放到队列里面! 
        等服务器处理完最基本最重要的数据库添加后再处理这些额外功能! 
        这就是消息队列的作用! 服务器不能同时处理两个任务. 所以就把这两个功能进行排队按先后执行.



🔸 异步处理场景 

    场景说明：用户注册后，需要发送注册邮件和发送注册信息，传统的做法有两种：串行方式、并行方式

    ⦿ 串行方式
        将注册信息写入数据库成功后，发送注册邮件，然后发送注册短信，而所有任务执行完成后，返回信息给客户端

    ⦿ 并行方式
        将注册信息写入数据库成功后，同时进行发送注册邮件和发送注册短信的操作。
        而所有任务执行完成后，返回信息给客户端。同串行方式相比，并行方式可以提高执行效率，减少执行时间。

    上面的比较可以发现，假设三个操作均需要50ms的执行时间，排除网络因素，
    则最终执行完成，串行方式需要150ms，而并行方式需要100ms。

    则串行方式1秒(1000ms)内可执行的请求量为1000/150，不到7次；
    并行方式1秒内可执行的请求量为1000/100，为10次。

    由上可以看出，传统串行和并行的方式会受到系统性能的局限，那么如何解决这个问题？
    我们需要引入消息队列，将不是必须的业务逻辑，异步进行处理.
    也就是说 我们只执行最重要的功能: 把注册信息写入数据集. 邮件和短信.暂时先不运行.有空再运行.
    用户的响应时间基本相当于将用户数据写入数据库的时间，发送注册邮件、发送注册短信的消息在写入消息队列后，即可返回执行结果，写入消息队列的时间很快，几乎可以忽略，也有此可以将系统吞吐量提升至20QPS，比串行方式提升近3倍，比并行方式提升2倍。


🔸 应用解耦

    场景说明：用户下单后，订单系统需要通知库存系统。

    传统的做法为：订单系统调用库存系统的接口:   订单系统 ➜ 库存系统

    传统方式具有如下缺点：
    -1. 假设库存系统访问失败，则订单减少库存失败，导致订单创建失败
    -2. 订单系统同库存系统过度耦合

    如何解决上述的缺点呢？需要引入消息队列，

    订单系统 --> 消息队列  <-- 库存系统

    订单系统：用户下单后，订单系统进行数据持久化处理，然后将消息写入消息队列，返回订单创建成功
    库存系统：使用拉/推的方式，获取下单信息，库存系统根据订单信息，进行库存操作。

    假如在下单时库存系统不能正常使用。
    也不影响正常下单，因为下单后，订单系统写入消息队列就不再关心其后续操作了。
    由此实现了订单系统与库存系统的应用解耦。

    至于库存是否有货,可以在下单前先检测一下.



🔸 流量削锋

    流量削锋也是消息队列中的常用场景，一般在秒杀或团抢活动中使用广泛。

    应用场景：秒杀活动，一般会因为流量过大，导致流量暴增，应用挂掉。

    为解决这个问题，一般需要在应用前端加入消息队列。
    可以控制参与活动的人数；
    可以缓解短时间内高流量对应用的巨大压力；

    用户请求(写入消息队列) --> 消息队列 <-- (根据规则读取秒杀请求)秒杀业务处理

    服务器在接收到用户请求后，首先写入消息队列。
    这时如果消息队列中消息数量超过最大数量，则直接拒绝用户请求或返回跳转到错误页面；

    秒杀业务根据秒杀规则读取消息队列中的请求信息，进行后续处理。




🔸 日志处理

    日志处理是指将消息队列用在日志处理中，比如Kafka的应用，解决大量日志传输的问题。架构简化如下：

    日志采集客户端 (写入) --> kafka 消息队列 <-- (订阅消费) 日志处理应用

    日志采集客户端：负责日志数据采集，定时写受写入Kafka队列；
    Kafka消息队列：负责日志数据的接收，存储和转发；
    日志处理应用：订阅并消费kafka队列中的日志数据；

    还是拿秒杀活动来举例. 秒杀期间订单多了 秒杀期间的日志肯定也多了.
    但是非秒杀期间日志其实非常少的.  同样的我们可以用消息队列来处理日志的突发流量!

    当然这要配合 ELK. 一起效果最好. ELK 本来就是日志处理的强项.

    Kafka：接收用户日志的消息队列。

    Logstash：做日志解析，统一成JSON输出给Elasticsearch。
    Elasticsearch：实时日志分析服务的核心技术，实时的数据存储服务，兼具强大的搜索和统计功能。
    Kibana：基于Elasticsearch的数据可视化组件，超强的数据可视化能力是众多公司选择ELK stack的重要原因。




🔸 消息通讯

    消息通讯是指，消息队列一般都内置了高效的通信机制，因此也可以用在纯的消息通讯。比如实现点对点消息队列、聊天室等。

    点对点通讯: 客户端A 发布消息  --> 消息队列 <-- 客户端B 接收消息
    聊天室通讯: 客户端A 收发消息 <--> 消息队列 <--> 客户端B 收发消息


    客户端A、客户端B、直至客户端N订阅同一消息队列，进行消息的发布与接收，即可实现聊天通讯方案架构设计。









🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸


🔸 异步通信

    很多时候，用户不想也不需要立即处理某些消息。
    消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。
    想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

    将耗时的同步操作，变成排队的异步处理方式，
    也就是把一个任务 分成紧急任务 和 非紧急任务.

    就那用户注册来说.
    首先处理紧急任务,让用户可以登录!!!. 因为用户只关心这些重要的东西!
    然后处理一般任务,比如各种个性化功能. 这些功能是企业关心的! 目的是为了能留住用户!


🔸 顺序保证

    在大多使用场景下，数据处理的顺序都很重要。
    大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。
    Kafka保证一个Partition内的消息的有序性。


🔸 缓冲
    在任何重要的系统中，都会有需要不同的处理时间的元素。
    例如，加载一张图片比应用过滤器花费更少的时间。
    消息队列通过一个缓冲层来帮助任务最高效率的执行———写入队列的处理会尽可能的快速。
    该缓冲有助于控制和优化数据流经过系统的速度。


🔸 解耦

    解耦是消息队列要解决的最本质问题。
    所谓解耦，简单点讲就是一个事务，只关心核心的流程。
    而需要依赖其他系统但不那么重要的事情，有通知即可，无需等待结果。
    换句话说，基于消息的模型，关心的是“通知”，而非“处理”。

    举一个例子，对于外卖的订单系统

    订单最终支付成功之后可能需要给用户发送短信积分什么的.
    这里有两件事情: 付款成功通知(核心功能) + 短信积分通知(辅助功能)
    任何事情都是要花一定的时间的!

    用户最关心的是付款有没有成功, 积分啥的可有可无.

    正确的做法是 只要对方付款成功了. 就给用户发 付款成功的通知.
    而不是在用户付款成功后 还要等那什么积分功能处理完成 才给用户发通知.

    因为外卖这种高峰期非常集中! 服务器只处理付款就有点困难了, 你还要同时处理积分的话 
    那么用户需要等上几分钟才能获得结果.这样的体验是非常差的!




🔸 最终一致性

    最终一致性指的是两个系统的状态保持一致，要么都成功，要么都失败。
    当然有个时间限制，理论上越快越好，但实际上在各种异常的情况下，
    往往会有一定的延迟后才能达到最终一致状态，但最后两个系统的状态是一样的。

    业界有一些为“最终一致性”而生的消息队列，如Notify（阿里）、QMQ（去哪儿）等，
    其设计初衷，就是为了交易系统中的高可靠通知! 

    用银行转账过程来理解最终一致性:
        转账的需求很简单，如果A系统扣钱成功，则B系统加钱一定成功。反之则一起回滚，像什么都没发生一样。
        然而，这个过程中存在很多可能的意外：

        A扣钱成功，调用B加钱接口失败。
        A扣钱成功，调用B加钱接口虽然成功，但获取最终结果时网络异常引起超时。
        A扣钱成功，B加钱失败，A想回滚扣的钱，但A机器down机。
        可见，想把这件看似简单的事真正做成，真的不那么容易。


    所有跨VM的一致性问题，从技术的角度讲通用的解决方案是：
        最终一致性，主要是用“记录”和“补偿”的方式。
        在做所有的不确定的事情之前，先把事情记录下来，然后去做不确定的事情，
        结果可能是：成功、失败或是不确定，“不确定”（例如超时等）可以等价为失败。

        成功就可以把记录的东西清理掉了，
        对于失败和不确定，可以依靠定时任务等方式把所有失败的事情重新搞一遍，直到成功为止。



🔸 广播
    消息队列的基本功能之一是进行广播。
    如果没有消息队列，每当一个新的业务方接入，我们都要联调一次新接口。
    有了消息队列，我们只需要关心消息是否送达了队列，至于谁希望订阅，是下游的事情，无疑极大地减少了开发和联调的工作量。




🔸 灵活性 & 峰值处理能力

    在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量并不常见；
    如果为以能处理这类峰值访问为标准来投入资源随时待命无疑是巨大的浪费。
    使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

    前后端的处理能力是不同的!
    Web前端每秒承受上千万的请求，并不是什么神奇的事情，多加点机器,搭建一些LVS负载均衡设备,Nginx等即可。
    但数据库的处理能力却十分有限，即使使用SSD加分库分表，单机的处理能力仍然在万级。
    由于成本的考虑，我们不能奢求数据库的机器数量追上前端。

    这种问题同样存在于系统和系统之间，
    如短信系统速度卡在网关上（每秒只能处理几百次请求），跟前端的并发量不是一个数量级。
    但用户晚上个半分钟左右收到短信，一般是不会有太大问题的。

    利用 消息队列 这个中间系统暂存前后端的通信内容，
    并在后端有能力处理这些消息的时候，再处理这些消息，是一套相对较通用的方式。

    总而言之，消息队列不是万能的。对于需要强事务保证而且延迟敏感的，RPC是优于消息队列的。
    对于一些无关痛痒，或者对于别人非常重要但是对于自己不是那么关心的事情，可以利用消息队列去做。
    支持最终一致性的消息队列，能够用来处理延迟不那么敏感的“分布式事务”场景.
    当上下游系统处理能力存在差距的时候，利用消息队列做一个通用的“漏斗”。
    在下游有能力处理的时候，再进行分发。
    如果下游有很多系统关心你的系统发出的通知的时候，果断地使用消息队列吧。




🔸 分布式

    通过对消费者的横向扩展，降低了消息队列阻塞的风险，以及单个消费者产生单点故障的可能性
    当然消息队列本身也可以做成分布式集群


🔸 可靠性/冗余

    消息队列一般会把接收到的消息存储到本地硬盘上
    当消息被处理完之后，存储信息根据不同的消息队列实现，有可能将其删除
    这样即使应用挂掉或者消息队列本身挂掉，消息也能够重新加载。

    有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。
    消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。
    许多消息队列所采用的"插入-获取-删除"范式中，在把一个消息从队列中删除之前，
    需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。





🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 常用MQ 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 RabbitMQ

    一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP, STOMP， 
    也正因如此，它非常重量级，更适合于企业级的开发。
    同时实现了Broker构架，这意味着消息在发送给客户端时先在中心队列排队。
    对路由，负载均衡或者数据持久化都有很好的支持。


🔸 Redis

    Redis是一个基于Key-Value对的NoSQL数据库，开发维护很活跃。
    虽然它是一个Key-Value数据库存储系统，但它本身支持MQ功能，所以完全可以当做一个轻量级的队列服务来使用。

    对于RabbitMQ和Redis的入队和出队操作，各执行100万次，每10万次记录一次执行时间。
    实验表明：
    入队时，当数据比较小时Redis的性能要高于RabbitMQ，而如果数据大小超过了10K，Redis则慢的无法忍受；
    出队时，无论数据大小，Redis都表现出非常好的性能，而RabbitMQ的出队性能则远低于Redis。




🔸 ZeroMQ

    ZeroMQ号称最快的消息队列系统，尤其针对大吞吐量的需求场景。
    ZeroMQ能够实现RabbitMQ不擅长的高级/复杂的队列，但是开发人员需要自己组合多种技术框架，
    技术上的复杂度是对这MQ能够应用成功的挑战。
    ZeroMQ具有一个独特的非中间件的模式，你不需要安装和运行一个消息服务器或中间件，因为你的应用程序将扮演这个服务器角色。你只需要简单的引用ZeroMQ程序库，可以使用NuGet安装，然后你就可以愉快的在应用程序之间发送消息了。但是ZeroMQ仅提供非持久性的队列，也就是说如果宕机，数据将会丢失。其中，Twitter的Storm 0.9.0以前的版本中默认使用ZeroMQ作为数据流的传输（Storm从0.9版本开始同时支持ZeroMQ和Netty作为传输模块）。

🔸 ActiveMQ

    ActiveMQ是Apache下的一个子项目。 类似于ZeroMQ，它能够以代理人和点对点的技术实现队列。
    同时类似于RabbitMQ，它少量代码就可以高效地实现高级应用场景。

🔸 Kafka/Jafka

    Kafka是Apache下的一个子项目，是一个高性能跨语言分布式发布/订阅消息队列系统，
    而Jafka是在Kafka之上孵化而来的，即Kafka的一个升级版。
    具有以下特性：
    快速持久化，可以在O(1)的系统开销下进行消息持久化；
    高吞吐，在一台普通的服务器上既可以达到10W/s的吞吐速率；
    完全的分布式系统，Broker、Producer、Consumer都原生自动支持分布式，自动实现负载均衡；
    支持Hadoop数据并行加载，对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。
    Kafka通过Hadoop的并行加载机制统一了在线和离线的消息处理。
    Apache Kafka相对于ActiveMQ是一个非常轻量级的消息系统，除了性能非常好之外，还是一个工作良好的分布式系统。





🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 Kafka 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 why  

    Nginx、Hadoop、数据库...都会不断产生各种信息(不仅仅是日志)! 
    收集并分析这些信息就成了刚需.如果只要处理日志可以用ELK, 但如果是别的数据最好用 Kafka
 
    页面访问量PV: page view 、被查看内容方面的信息、搜索情况 对网站来说非常重要.
    这种数据的处理方式一般是把各种活动以日志的形式写入到某种文件.然后周期性的对这些文件进行统计. 
    kafka 可以更好的处理这些问题.

    kafka：一个分布式消息系统; 有着轻量级 + 高吞吐的优势; 还可以水平扩展(建kafka集群)
    Kafka可以用来做消息队列、流式处理（一般结合storm）、日志聚合等。

    高吞吐率。即使在非常廉价的商用机器上也能做到单机支持每秒100K条以上消息的传输。



🔸 消息持久化

    很多软件为了提升效率.一般恨不得把所有数据都扔到内存里.然后定期写入到磁盘.

    现在操作系统 都会把空闲内存作为 磁盘缓存! 想不用都难, 
    这也是为什么Linux 不管你有多少内存都能把你用掉的原因

    这样就出现问题了. 软件本身已经把数据写在内存里了, 然后软件定期一个备份到磁盘.
    但是这个备份其实也会被操作系统当成 磁盘缓存 缓存到空闲内存中! 
    这就导致了 内存中有两份数据!  导致浪费!!!

    所以kafka决定之间使用页面缓存! 



🔸 模型    

    Producer ➜ Broker ➜ Consumer  

        Producer：消息生产者，  负责产生和发送消息到 Broker；
        Broker：  消息处理中心. 负责消息存储、确认、重试等，一般其中会包含多个 queue；
        Consumer：消息消费者，  负责从 Broker 中获取消息，并进行相应处理；


🔸 PUSH vs Pull

    对于消息的消费. ActiveMQ 使用PUSH模型.  Kafka 使用Pull模型. 两者各有利弊.

    对于PUSH，broker很难控制数据发送给不同消费者的速度，
    而PULL可以由消费者自己控制，
    
    但是PULL模型可能造成消费者在没有消息的情况下盲等，这种情况下可以通过long polling机制缓解，
    而对于几乎每时每刻都有消息传递的流式系统，这种影响可以忽略。



🔸 可靠性 

    ⦿ 消息投递的可靠性. 
        一个消息如何算投递成功.
        Kafka 提供了三种模式.
        1: 什么都不管,发出就当成功.
        2: 对于主从模型,所有主从都接收到消息时才算投递成功. 可靠性最高,但是性能低!!!
        3: 对于主从模型,只要主确认收到消息就算投递成功!  可靠性/性能兼顾. 绝大多数情况都选用这种.


    ⦿ broker 上的可靠性.
        消息会持久化到磁盘上.  
        如果broker 正常关机. 里面的数据不会丢失.
        如果broker 异常关机. 页面缓存中的数据来不行写入磁盘就会造成消息丢失! 


    ⦿ 消息消费的可靠性
        kafka 提供的是 AT least once 模型. 因为消息的读取进度由offset提供.
        offset 可以由消费者自己维护.  也可以由 zookeeper 维护. 
        但是当 消息消费后 consumer 挂掉. offset 没即时写回. 就有可能发生重复读取的情况.


    ⦿ zookepper 的可靠性
        这个挂了. 一起都完了.
        增强可靠性的方式就是把zookeeper也部署进集群





🔸 Kafka 作用 

    • 消息系统: 解耦和生产者和消费者、缓存消息等! 
               但是Kafka的作用不仅仅是消息队列!

    • 用户活动跟踪! 
        Kafka经常被用来记录web用户或者app用户的各种活动，如浏览网页、搜索、点击等活动，
        这些活动信息被各个服务器发布到kafka的topic中，然后订阅者通过订阅这些topic来做实时的监控分析，或者装载到hadoop、数据仓库中做离线分析和挖掘。

    • 运营指标：
        Kafka也经常用来记录运营监控数据。包括收集各种分布式应用的数据，生产各种操作的集中反馈，比如报警和报告。

    • 流式处理：比如spark streaming和storm






🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸  🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸



