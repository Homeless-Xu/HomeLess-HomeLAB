🔸 本文结构

⦿ 本地文件系统 
    • 分区
    • 格式化
    • inode 
    • FAT、exFAT、NTFS、HFS、EXT2


⦿ 分布式文件系统


⦿ Hadoop 
    • 大数据
    • MapReduce
    • Hive
    • HDFS
    • Shark




🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 本地文件系统 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 机械硬盘

    虽然现在SSD 很流行了. 但是一些 机械硬盘的知识还是非常有用的!

    机械硬盘的结构可以看成CD/DVD 那样的光盘!  由很多不同直径的圈组成!
    每一个圈叫柱面.  每个圈还能分成扇区 (最小的物理存储单位) 扇区主要有 512Bytes 和 4K 两种格式.



🔸 为什么要分区
  
    ❗️当今，分区的主要原因是让数据与系统分离，便于维护。❗️

    ⦿ Windows 
      运行久了 会产生很多垃圾文件. 和文件碎片.导致运行速度变慢.
      虽然可以删除垃圾文件,也能进行磁盘整理. 但是刚刚安装的系统永远是最快的. 
      为了让重装系统不丢失自己的数据. 一般会对硬盘进行分区.C盘装系统. 其他盘装资料.
      重装系统的时候 先格式化掉C盘 然后还是把系统安装到C盘. 这样就可以了.
      重装后的系统. 在其他分区的数据还在! 
      但是程序的话.你必须要重新安装.

    ⦿ Linux 
      一般都是一个 根分区(/分区)  加上一个 swap 分区.  最多还会把 /home 也单独分区.

    ⦿ Mac
      主要就三类资料: 系统文件、个人数据、软件程序.
        • 系统文件集中在 /bin、/cores、/mach_kernel
        • 个人文件集中在 /Users
        • 程序文件集中在 /Applications

      分区后可将系统、数据、程序分到不同的分区上，任意一部分需要更新的时候，不会影响到其他部分。
      如果系统出了问题，那么格式化系统分区，
      恢复部分配置后，软件不用重装，用户数据依然存在。其他两个部分出现问题时类似。



🔸 分区格式

    • MBR ➜ 旧 ➜ 最多只能识别2T的硬盘; 4T的硬盘用MBR来分区. 只能识别2T.剩余的就不能用了..
    • GPT ➜ 新 ➜ 大容量磁盘 要用GPT 分区才行, 不然不能充分利用磁盘空间.
          👁‍🗨 就像32位的系统. 8G的内存只能识别出3.6G  要上64位系统才能识别出全部的内存.



🔸 为什么格式化 

    不同的操作系统 有不同的文件属性/权限.
    要将分区进行格式化. 成为操作系统能够利用的 文件系统格式.
      • Windows 98 用 FAT 文件系统.
      • Windows xp 用 NTFS 文件系统.
      • Linux      用 Ext2 文件系统  


    一般来说 一个分区只能格式化成一个文件系统. 
    但是新的 LVM 技术可以把一个分区格式化成多个文件系统.



🔸 文件系统

    管理好自己的磁盘文件系统 也是系统管理员的一个基本技能.
    分区太大会造成磁盘容量的浪费, 分区太小会造成文件没空间存储.

    文件其实由两部分数据组成: 文件实际内容 + 文件属性
    文件是含有非常多的额外属性!额外属性主要是为了保护数据. 例如 Linux 的 rwx 属性、文件最后修改时间...
    
    文件系统一般把这两部分分别存放在不同的区块. 还有一个超级区块 Superblock 
      • inode :       存放文件权限和属性, 一个文件一个 inode , inode 里有存放该文件件实际数据的 block 号码
      • data block :  存放实际数据, 文件太大的时候 会占用多个 block
      • superblock    记录整个文件系统的整体信息.包括 inode 与 block 的总量、使用量、剩余量等。


    任何文件系统格式的设计都是用来管理文件的!
    ❗️ 文件系统有很多种!  Linux 主要用 ext 系列. windows 主要用 FAT 和 NTFS ❗️

    ext4 是Linux 使用最广泛的文件系统.
    但是实际是还有很多文件系统! 
    RHEL 7 默认用 XFS 文件系统.
    openSUSE 默认用 btrfs 文件系统.

    btrfs 对ssd 特意进行了优化! ext4 对ssd 也有一点优化. NTFS 对ssd几乎没有优化!


    windows 是按照物理存储来确定层级的. 每加一个硬盘就会分配一个盘符(D盘、E盘、F盘...)
    Linux 无论你有几百个硬盘. 它默认都是那几个文件夹. 和硬盘没有关系.
    两个操作系统对文件的管理思维是不一样的!
    Linux 倾向业务逻辑. 本来就是给多人用的. 你不需要去关注硬盘..
    Windows 让你感觉这台电脑就是个人的. 硬盘怎么管理.文件怎么放都随便你..




 🔸 inode

    inode 记录的文件数据至少有下面这些:
      • 该文件的存取模式 -----------read/write/excute
      • 该文件的拥有者与群组--------owner/group
      • 该文件的容量
      • 该文件创建或状态改变的时间--ctime
      • 最近一次的读取时间----------atime
      • 最近修改的时间--------------mtime
      • 定义文件特性的旗标----------flag  如 SetUID...
      • 该文件真正内容的指向--------pointer




🔸 FAT 

    FAT 虽然是兼容性最好的文件格式. 但是有不少缺点.
    • 无法对 FAT分区里的文件设置权限!
    • 不能执行撤销删除操作
    • 分区大小超过200M 时FAT 的性能会快速降低!
    • FAT 单文件最大 4G


🔸 exFAT 

    • 微软出的. 虽说无缝兼容 Win 个 Mac ,但是好像非常多的坑! 建议别碰这货...
    • U盘可以试试这个格式. 硬盘不要用这个..
    • 啥智能电视一般不支持这个格式的. 还是用 ntfs 吧



🔸 NTFS 

      对 FAT 系统的改进.增加了一些功能 也增强了可靠性.
    • 额外的时间戳提供上次访问文件的时间。
    • 硬链接: 两个位于不同目录不同文件名的文件指向相同的数据.
    • 分区大小可以达到 16TB
    • 即使硬盘有坏道也能抢救内部数据.
    • NTFS 在 Mac 中只能读取 不能写入!


🔸HFS+

    苹果系统的文件格式. 


🔸 EXT2 

    我们知道了 文件的真实数据是存放在 data block 中的. 
    Ext2 文件系统支持的block大小有三种: 1K,2K,4K
    ❗️格式化的时候 block大小就固定了!  每个block 都有编号,方便 inode记录❗️

    ⦿ 不同的 block大小. 会有不同的限制
        Block 大小            1KB       2KB      4KB
        最大单一文件限制      16GB      256GB    2TB
        最大文件系统总容量    2TB       8TB      16TB


    ⦿ Ext2 文件系统的 block 限制 
      • 原则上，block 的大小与数量在格式化完就不能够再改变了（除非重新格式化）；
      • 每个 block 内最多只能够放置一个文件的数据；
      • 承上，如果文件大于 block 的大小，则一个文件会占用多个 block 数量；
      • 承上，若文件小于 block ，则该 block 的剩余容量就不能够再被使用了（磁盘空间会浪费）。

      由于每个 block 仅能容纳一个文件的数据而已，
      如果你的文件都非常小，但是你的 block 在格式化时却选用最大的 4K 时，可能会产生一些容量的浪费喔！
      如果你的文件非常大. 上百G的4K电影. 用 1KB 的block格式化后. 单个文件最大只能是16G的.这时候单个电影就几百G的就储存不了. 
      当然限制硬盘都非常大了... 直接用 4K的吧. 浪费点也没事. 


🔸 Ext4

    Centos 6 默认用 Ext4 文件系统了, 
    Ext4 文件系统的 inode 容量已经可以扩大到 256Bytes 了，
    更大的 inode 容量，可以纪录更多的文件系统信息，包括新的 ACL 以及 SELinux 类型等， 
    当然，可以纪录的单一文件大小达 16TB 且单一文件系统总容量可达 1EB 哩！

    • Ext4 不支持文件快照 (LVM 支持)











🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 集群文件系统 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 简介

    读取一整块机械硬盘要很长时间.. 写入时间则更长! 一般是读取的3倍.
    电脑如果是个人使用数据不会太多. 一台台式机可以插 6个+ 的硬盘. 足够使用了.
    但是企业数据非常多!   需要存储海量的文档、图片、视频 ... 
    一台服务器肯定存不下整个公司的数据的,何况还要考虑数据的安全性.备份等等.
    那么就要使用多台服务器来搭建存储集群了. 也就是分布式存储集群了.
    集群不是有电脑就可以的. 还要安装软件的啊. 
    分布式集群也有很多软件选择:GFS、HDFS.... 各自适用于不同的领域.

    分布式存储目前多借鉴Google GFS的经验，
    利用众多的服务器搭建一个分布式文件系统，再在这个分布式文件系统上实现相关的数据存储业务

    集群文件系统是指  把集群内的所有储存空间 进行整合、虚拟化、并对外提供访问的文件系统.
    和 NTFS 这类的本地文件系统的目的不一样. 
    集群文件系统 运行在集群中.   目的是为了 扩展性.
    本地文件系统 运行在单机环境. 


🔸 分布式

    分布式存储系统可以理解为多台单机存储系统的各司其职、协同合作，统一的对外提供存储的服务。
    分布式存储简单的来说，就是将数据分散存储到多个数据存储存储服务器上。
    利用分布式技术将多台服务器中的 HDD、SDD 组成一个大规模的存储资源池.
    
    HDFS、Swift 等互联网常用的大规模集群文件系统无一例外都属于分布式集群文件系统.

    由于是分布式的.那么各节点就需要通过网络来通信. 
    但是 只要存在沟通. 由于昂贵的沟通成本(CAP理论)导致其实现原理会变得复杂.
    当然 这只是实现困难. 
    用户使用还是非常简单的. 能成功快速增删读写文件就ok了，根本不关心这是本地存储还是分布式存储.

    集群难免会进行数据读写. 怎么读取 去哪台服务器读取. 怎么写入. 在哪台服务器上进行写入都是问题.

    随着集群规模扩大 节点不可用、网络异常、磁盘损坏、等各种故障都有可能发生.
    集群服务的容错性、数据可用性 都是分布式文件系统的重要衡量指标.
    一旦发生故障.集群必须仍然能正常通过服务. 可以进行数据迁移 还要有修复的能力
    集群服务通过心跳机制完成各个节点间的负载、死活状态、故障检测.
    通过节点镜像、数据迁移操作来修复故障节点.




🔸 分布式(虚拟化)
    虚拟化的场景下, 使用分布式存储无疑是一个非常正确的选择.
    openStack 就用了 swift 这个对象存储





🔸 GFS  
    Google File System（大规模分散文件系统）

    Google公司为了满足自己公司需求而开发的基于Linux的专有分布式文件系统.
    尽管Google公布了该系统的一些技术细节，但Google并没有将该系统的软件部分作为开源软件发布。







🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 Hadoop 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 大数据存储

    大数据, 首先你要存的下大数据! 
    传统文件系统是单机的. 不能横跨不同的机器.
    HDFS 的设计本质上是为了大类的数据能横跨成百上千台机器,但是用户看到只是一个文件系统.
    比如我要获取 HDFS 里的某个视频文件. 路径只有一个. 但是实际的数据是存放在很多不同的机器上的.
    你作为用户不需要知道这些.  就像传统的本地文件系统.你根本不关心文件分散在硬盘中的什么扇区. 
    HDFS 为你管理这些数据.


🔸 大数据计算 

    数据存储问题解决了(把文件分散到其他服务器中),你要考虑怎么处理数据了.
    之所以叫大数据. 是因为大数据都是 成T上P 级别的数据.
    什么叫处理呢...
    比如你收集了所有人的谷歌搜索记录,你想找出那个关键词最热门! 
    关键词是非常有价值的... 比如SEO、广告都会用到.
    既然是热门关键词当然是有时效性能的.
    我现在给你10T的数据. 如果你要花费10天半个月才能得到结果..那么完全没意义了.
    所以不仅是存储需要用到集群. 计算也需要用到集群! 让多台电脑一起计算,加快速度.
    这时候面临怎么分配工作的问题了.
    比如某台电脑在计算过程中挂了. 那么要重新启动相应的任务.
    各个电脑之间应该相互通信.才能完成复杂的计算.
    这就是 MapReduce/TEZ/Spark 的功能.
    MapReduce 是第一代计算引擎. Tez 和 Spark 是第二代计算引擎.
    虽然 MapReduce 已经老了.但是一些概念还是值得学习的!


🔸 MapReduce

    MapReduce = Map + Reduce(简化的意思) 

    如果要你统计 HDFS系统中的某个文本文件(几个TB大小的文件) 里各个词的出现频率! 
    这个文本文件是储存在各个集群节点中的. 不是储存在某个节点中的

    你启动了一个MapReduce程序。
    Map阶段，几百台机器同时读取这个文件的各个部分，分别把各自读到的部分分别统计出词频，
    产生类似(hello, 12100次)，(world，15214次)等等这样的集合

    这几百台机器各自都产生了如上的集合，然后又有几百台机器启动Reduce处理。
    一台reduce 处理一个单词.  比如 reduce 机器1 汇总 hello 这个单词; 比如 reduce 机器2 汇总 world 这个单词
    每个Reducer都如上处理，你就得到了整个文件的词频结果...

    Map+Reduce的简单模型很黄很暴力，虽然好用，但是很笨重.  所以就有了 第二代计算引擎: Spark / Tez ...
    
    而且 MapReduce 是需要写代码的! 而且代码写起来也麻烦!
    就像编程语言一样.实现同样的功能. C++ 可能需要几十行, python 可能一行就够了!
    所以就有了 Hive 这东西了.
    

🔸 Hive 

    用的SQL, 把脚本和SQL语言 翻译成 mapreduce ! 
    于是 数据分析师 就不再需要会开发语言了! 因为学 SQL 非常简单,要学个开发语言还是蛮困难的!
    于是 Hive 就火了, 毕竟不是谁都会编程的! 
    Hive 成为了 大数据仓库的核心组件.  很多公司都开始使用Hive.因为易写易改，一看就懂，容易维护。



🔸 Hadoop 

　　❗️❗️Hadoop是一个处理大规模数据的软件平台,专为大规模数据分析而设计的. 用集群对海量数据进行分布式计算.❗️❗️

    Hadoop = HDFS（文件系统，提供了海量数据的存储）+ Mapreduce（对数据进行处理）

　　Hadoop非常适合应用于大数据存储和大数据分析的应用，
    适合搭建超大规模的服务器集群(上万个服务器组成的...)，支持PB级的存储容量。
    这是传统数据库不能超越的一点也是最有优势的一点。

　　⦿ HDFS
        Hadoop Distributed File System    Hadoop分布式文件系统
        它是一个高度容错性的系统，适合部署在廉价的机器上。
        HDFS能提供高吞吐量的数据访问，适合那些有着超大数据集的应用程序。

　　⦿ MapReduce
        一套从海量源数据提取分析元素最后返回结果集的编程模型，
        将文件分布式存储到硬盘是第一步，而从海量数据中提取分析我们需要的内容就是MapReduce做的事了。



🔸 HDFS

    Hadoop Distribute File System 的简称，中文意思就是 Hadoop 分布式文件系统

    HDFS 是主从架构.
    配置 HDFS 集群成本主要在于内存和硬盘.
    Master 需要大量的内存.
    Slave  需要大量的硬盘. 


🔸 HDFS 设计理念

    ⦿ 存储超大文件
        这里的“超大文件”是指几百MB、GB甚至TB级别的文件。

    ⦿ 最高效的访问模式是 一次写入、多次读取(流式数据访问)
        HDFS存储的数据集作为hadoop的分析对象。
        在数据集生成后，长时间在此数据集上进行各种分析。
        每次分析都将设计该数据集的大部分数据甚至全部数据，
        因此读取整个数据集的时间延迟比读取第一条记录的时间延迟更重要。

    ⦿ 运行在普通廉价的服务器上
        HDFS设计理念之一就是让它能运行在普通的硬件之上，即便硬件出现故障，也可以通过容错策略来保证数据的高可用。


🔸 HDFS 忌讳

    ⦿ 将HDFS用于对数据访问要求低延迟的场景
        由于HDFS是为高数据吞吐量应用而设计的，必然以高延迟为代价。
        分布式系统有个难以回避的问题: 文件不在一个磁盘. 导致读取方面的延时.

    ⦿ 存储大量小文件
        HDFS中元数据（文件的基本信息）存储在namenode的内存中，而namenode为单点，小文件数量大到一定程度，namenode内存就吃不消了。


🔸 HDFS 基本概念

    • 数据块（block）：
        大文件会被分割成多个block进行存储，block大小默认为64MB。
        每一个block会在多个datanode上存储多份副本，默认是3份。

    • namenode：namenode负责管理文件目录、文件和block的对应关系以及block和datanode的对应关系。

    • datanode：datanode就负责存储了，当然大部分容错机制都是在datanode上实现的。



🔸 Hadoop 作用

    hadoop擅长日志分析，facebook就用Hive来进行日志分析，
    2009年时facebook就有非编程人员的30%的人使用HiveQL进行数据分析；
    淘宝搜索中的自定义筛选也使用的Hive；

    当然 Hadoop 还有很多作用搜索、数据分析、视频图像分析、数据保存...







🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸 Shark 🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸🔸

🔸 Shark 起因

    由于Hadoop在企业生产中的大量使用，HDFS上积累了大量数据，
    为了给熟悉RDBMS但又不理解MMapReduce的技术人员提供快速上手的工具，Hive应运而生。
    Hive的原理是将SQL语句翻译成MapReduce计算。

    但是，MapReduce计算过程中大量的中间磁盘落地过程消耗了大量的I/O，降低了运行效率，
    为了提供SQL-on-Hadoop的效率，Shark出现了。

🔸 Shark 简介

    Shark是Spark生态环境的组件之一，
    它修改了Hive中的内存管理、物理计划和执行三个模块，
    使得SQL语句直接运行在Spark上，从而使得SQL查询的速度得到10-100倍的提升。


🔸 Shark 之死

    2014年6月1日，停止对Shark的开发，将所有资源放sparkSQL项目上, 至此，Shark的发展画上了句话。

    随着Shark的结束，两个新的项目应运而生：SparkSQL和Hive on Spark。
    其中SparkSQL作为Spark生态的一员继续发展，而不再受限于Hive，只是兼容Hive；
    而Hive on Spark是一个Hive的发展计划，该计划将Spark作为Hive的底层引擎之一，
    也就是说，Hive将不再受限于一个引擎，可以采用Map-Reduce、Tez、Spark等引擎。


🔸 sparkSQL 

    SparkSQL无论在数据兼容、性能优化、组件扩展方面都得到了极大的方便，真可谓“退一步， 海阔天空”。

    数据兼容方面 
        不但兼容hive，还可以从RDD、parquet文件、JSON文件中获取数据，
        未来版本甚至支持获取RDBMS数据以及cassandra等NOSQL数据
        
    性能优化方面 
        除了采取In-Memory Columnar Storage、byte-code generation等优化技术外、
        将会引进Cost Model对查询进行动态评估、获取最佳物理计划等等
    
    组件扩展方面 
        无论是SQL的语法解析器、分析器还是优化器都可以重新定义，进行扩展




